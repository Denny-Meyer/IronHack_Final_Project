{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Docking Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "## !pip install -e ../gym_space_docking/\n",
    "\n",
    "loc = os.popen('pip3 show gym_space_docking').readlines()[7].split()[1]\n",
    "\n",
    "\n",
    "sys.path.append(loc)\n",
    "\n",
    "\n",
    "import gym\n",
    "import os\n",
    "import gym_space_docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include Network\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create enviroment pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "/Users/denny/Documents/workspace_ironhack/IronHack_Final_Project/gym_space_docking/gym_space_docking/envs\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('space_docking-v0')\n",
    "#print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "#print(env.observation_space)\n",
    "#print(type(env.action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "map, reward, done, info = env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(map, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocess_observations(map), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle observations\n",
    "\n",
    "# handle image scaling and resizing to fit the image in input data\n",
    "\n",
    "def preprocess_observations(obs):\n",
    "    # ToDo need love to work\n",
    "    img = obs\n",
    "    img = img.mean(axis=2)\n",
    "    img = (img - 128) / 128 -1\n",
    "\n",
    "    return img.reshape(88,80,1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create DQN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "input_height = 88\n",
    "input_width = 80\n",
    "input_channels = 1\n",
    "conv_n_maps = [32,64,64]\n",
    "conv_kernel_sizes = [(8,8), (4,4), (3,3)]\n",
    "conv_strides = [4, 2, 1]\n",
    "conv_paddings = ['SAME'] * 3\n",
    "conv_activation = [tf.nn.relu] * 3\n",
    "n_hidden_in = 64 * 11 * 10 # 64 maps with size 11x10\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n# -> ToDo define in enviroment \n",
    "initializer =  tf.keras.initializers.VarianceScaling()# tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state\n",
    "    with tf.compat.v1.variable_scope(name) as scope:\n",
    "        for n_maps, kernel_size, strides, padding, activation in zip(\n",
    "            conv_n_maps, conv_kernel_sizes, conv_strides,\n",
    "            conv_paddings, conv_activation):\n",
    "            \n",
    "            prev_layer = tf.compat.v1.layers.conv2d(\n",
    "                prev_layer, filters=n_maps, kernel_size= kernel_size,\n",
    "                strides= strides, padding=padding, activation=activation,\n",
    "                kernel_initializer= initializer)\n",
    "            \n",
    "            last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1, n_hidden_in])\n",
    "            \n",
    "            hidden = tf.compat.v1.layers.dense(last_conv_layer_flat, n_hidden, \n",
    "                                                activation=hidden_activation,\n",
    "                                                kernel_initializer=initializer)\n",
    "            \n",
    "            outputs = tf.compat.v1.layers.dense(hidden, n_outputs, \n",
    "                                                kernel_initializer=initializer)\n",
    "        \n",
    "        trainable_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \n",
    "                                                    scope=scope.name)\n",
    "        \n",
    "        trainable_vars_by_name = {var.name[len(scope.name):] : var for var in trainable_vars}\n",
    "\n",
    "        return outputs, trainable_vars_by_name\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "X_state = tf.compat.v1.placeholder(tf.float32, shape=[None, input_height, input_width, input_channels])\n",
    "online_q_values, online_vars = q_network(X_state=X_state, name='q_networks/online')\n",
    "target_q_values, target_vars = q_network(X_state=X_state, name='q_networks/target')\n",
    "\n",
    "copy_obs = [target_var.assign(online_vars[var_name]) for var_name, target_var in target_vars.items()]\n",
    "copy_online_to_target = tf.group(*copy_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_action = tf.compat.v1.placeholder(tf.int32, shape=[None])\n",
    "q_value = tf.reduce_sum(target_q_values * tf.one_hot(X_action, n_outputs), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.compat.v1.placeholder(tf.float32, shape=[None, 1])\n",
    "error = tf.abs(y - q_value)\n",
    "clipped_error = tf.clip_by_value(error, 0.0, 1.0)\n",
    "linear_error = 2*(error - clipped_error)\n",
    "loss = tf.compat.v1.reduce_mean(tf.square(clipped_error) +linear_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "optimizer = tf.compat.v1.train.MomentumOptimizer(learning_rate=learning_rate,name='momentum', momentum=0.9, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "saver = tf.compat.v1.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "replay_memory_size = 500000\n",
    "replay_memory = deque([], maxlen=replay_memory_size)\n",
    "\n",
    "def sample_memories(batch_size):\n",
    "    indicies = np.random.permutation(len(replay_memory))[:batch_size]\n",
    "    cols = [[], [], [], []] # state, action, rewards, next_state, continue\n",
    "    for idx in indicies:\n",
    "        memory = replay_memory[idx]\n",
    "        for col, value in zip(cols, memory):\n",
    "            col.append(value)\n",
    "    cols = [np.array(col) for col in cols]\n",
    "    return (cols[0], cols[1], cols[2].reshape(-1, 1), cols[3], cols[4].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor explore enviroment\n",
    "\n",
    "eps_min = 0.1\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 2000000\n",
    "\n",
    "def epsilon_greedy(q_values, step):\n",
    "    epsilon = max(eps_min, eps_max - (eps_max-eps_min) * step/eps_decay_steps)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        return np.argmax(q_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 4000000\n",
    "training_start = 10000\n",
    "training_interval = 4\n",
    "save_steps = 1000\n",
    "copy_steps = 10000\n",
    "discont_rate = 0.99\n",
    "skip_start = 90\n",
    "batch_size = 50\n",
    "iteration = 0\n",
    "checkpoint_path = './docking_dqn.ckpt'\n",
    "done = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-12 17:00:51.246717: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-12 17:00:51.319098: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 5) astro_85\n",
      "(18, 4) astro_85\n",
      "(19, 3) astro_85\n",
      "(17, 4) astro_85\n",
      "(17, 4) astro_85\n",
      "(19, 3) astro_85\n",
      "(20, 2) astro_85\n",
      "(19, 4) astro_85\n",
      "(20, 4) astro_85\n",
      "(20, 3) astro_85\n",
      "(22, 3) astro_85\n",
      "(22, 4) astro_85\n",
      "(21, 4) astro_85\n",
      "(21, 5) astro_85\n",
      "(16, 5) astro_85\n",
      "(17, 4) astro_85\n",
      "(18, 4) astro_85\n",
      "(16, 4) astro_85\n",
      "(16, 4) astro_85\n",
      "(16, 4) astro_85\n",
      "(14, 4) astro_85\n",
      "(14, 4) astro_85\n",
      "(7, 4) astro_85\n",
      "(7, 4) astro_85\n",
      "(11, 3) astro_85\n",
      "(10, 2) astro_85\n",
      "(9, 2) astro_85\n",
      "(7, 2) astro_85\n",
      "(7, 1) astro_85\n",
      "(4, 2) astro_85\n",
      "(1, 2) astro_85\n",
      "(1, 3) astro_85\n",
      "(1, 3) astro_85\n",
      "(1, 3) astro_85\n",
      "(1, 3) astro_85\n",
      "(1, 4) astro_85\n",
      "(21, 26) astro_94\n",
      "(20, 24) astro_94\n",
      "(20, 21) astro_94\n",
      "(20, 18) astro_94\n",
      "(18, 17) astro_94\n",
      "(18, 14) astro_94\n",
      "(16, 14) astro_94\n",
      "(16, 11) astro_94\n",
      "(15, 10) astro_94\n",
      "(14, 9) astro_94\n",
      "(12, 8) astro_94\n",
      "(12, 7) astro_94\n",
      "(10, 6) astro_94\n",
      "(10, 5) astro_94\n",
      "(8, 5) astro_94\n",
      "(7, 4) astro_94\n",
      "(5, 3) astro_94\n",
      "(5, 3) astro_94\n",
      "(5, 2) astro_94\n",
      "(3, 3) astro_94\n",
      "(5, 3) astro_94\n",
      "(5, 2) astro_94\n",
      "(5, 2) astro_94\n",
      "(4, 3) astro_94\n",
      "(4, 3) astro_94\n",
      "(4, 2) astro_94\n",
      "(4, 3) astro_94\n",
      "(4, 3) astro_94\n",
      "(3, 2) astro_94\n",
      "(29, 4) astro_57\n",
      "(29, 3) astro_57\n",
      "(29, 3) astro_57\n",
      "(28, 3) astro_57\n",
      "(29, 3) astro_57\n",
      "(27, 3) astro_57\n",
      "(29, 3) astro_57\n",
      "(29, 3) astro_57\n",
      "(28, 4) astro_57\n",
      "(27, 3) astro_57\n",
      "(27, 3) astro_57\n",
      "(26, 2) astro_57\n",
      "(26, 3) astro_57\n",
      "(26, 3) astro_57\n",
      "(27, 4) astro_57\n",
      "(27, 4) astro_57\n",
      "(28, 5) astro_57\n",
      "(29, 5) astro_57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/83__n5jj77s0p9pv81ccxck40000gn/T/ipykernel_4194/1802260584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# online dqn evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monline_q_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_greedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \"\"\"\n\u001b[0;32m--> 921\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use ref() instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5510\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5511\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5512\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_path + '.index'):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "        copy_online_to_target.run()\n",
    "    \n",
    "    while True:\n",
    "        step = global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "        iteration += 1\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            for skip in range(skip_start):\n",
    "                obs, reward, done, info = env.step(0)\n",
    "            state = preprocess_observations(obs)\n",
    "\n",
    "        # online dqn evaluate\n",
    "        q_values = online_q_values.eval(feed_dict={X_state: [state]})\n",
    "        action = epsilon_greedy(q_values, step)\n",
    "\n",
    "        # online dqn play\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_observations(obs)\n",
    "\n",
    "        # remember what happend\n",
    "        replay_memory.append((state, action, reward, next_state, 1.0 - done))\n",
    "        state = next_state\n",
    "\n",
    "        if iteration < training_start or iteration % training_interval != 0:\n",
    "            continue # only train after warmup period and at regular intervals\n",
    "\n",
    "        # get probe from memory\n",
    "        # use target dqn to get target q value\n",
    "        X_state_val, X_action_val, rewards, X_next_state_val, continues = (\n",
    "            sample_memories(batch_size=batch_size))\n",
    "        \n",
    "        next_q_values = target_q_values.eval(\n",
    "            feed_dict={X_state: X_state_val})\n",
    "\n",
    "        max_next_q_values = np.max(next_q_values, axis=1, keepdims=True)\n",
    "        y_val = rewards + continues * discont_rate * max_next_q_values\n",
    "\n",
    "        # train online dqn\n",
    "        training_op.run(feed_dict={X_state: X_state_val, X_action: X_action_val, y: y_val})\n",
    "\n",
    "        # copy online dqn to target dqn\n",
    "        if step % copy_steps == 0:\n",
    "            copy_online_to_target.run()\n",
    "        \n",
    "        # save regulary\n",
    "        if step % save_steps == 0:\n",
    "            saver.save(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cool, actally no big errors....time to work on the enviroment, passing the right values"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d2998af58360198af4f829ea7a2e55473ee9c83a4b3343387da68b4c68e0d61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('DA_Enviroment': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
