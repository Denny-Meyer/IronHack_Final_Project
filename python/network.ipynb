{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Docking Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "## !pip install -e ../gym_space_docking/\n",
    "\n",
    "loc = os.popen('pip3 show gym_space_docking').readlines()[7].split()[1]\n",
    "\n",
    "\n",
    "sys.path.append(loc)\n",
    "\n",
    "\n",
    "import gym\n",
    "import os\n",
    "import gym_space_docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include Network\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create enviroment pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "/Users/denny/Documents/workspace_ironhack/IronHack_Final_Project/gym_space_docking/gym_space_docking/envs\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('space_docking-v0')\n",
    "#print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "#print(env.observation_space)\n",
    "#print(type(env.action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle observations\n",
    "\n",
    "# handle image scaling and resizing to fit the image in input data\n",
    "\n",
    "def preprocess_observations(obs):\n",
    "    # ToDo need love to work\n",
    "    img = obs\n",
    "    img = img.mean(axis=2)\n",
    "    img = (img - 128) / 128 -1\n",
    "\n",
    "    return img.reshape(88,80,1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    map, reward, done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(map, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocess_observations(map), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create DQN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "input_height = 88\n",
    "input_width = 80\n",
    "input_channels = 1\n",
    "conv_n_maps = [32,64,64]\n",
    "conv_kernel_sizes = [(8,8), (4,4), (3,3)]\n",
    "conv_strides = [4, 2, 1]\n",
    "conv_paddings = ['SAME'] * 3\n",
    "conv_activation = [tf.nn.relu] * 3\n",
    "n_hidden_in = 64 * 11 * 10 # 64 maps with size 11x10\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n# -> ToDo define in enviroment \n",
    "initializer =  tf.keras.initializers.VarianceScaling()# tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state\n",
    "    with tf.compat.v1.variable_scope(name) as scope:\n",
    "        for n_maps, kernel_size, strides, padding, activation in zip(\n",
    "            conv_n_maps, conv_kernel_sizes, conv_strides,\n",
    "            conv_paddings, conv_activation):\n",
    "            \n",
    "            prev_layer = tf.compat.v1.layers.conv2d(\n",
    "                prev_layer, filters=n_maps, kernel_size= kernel_size,\n",
    "                strides= strides, padding=padding, activation=activation,\n",
    "                kernel_initializer= initializer)\n",
    "            \n",
    "            last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1, n_hidden_in])\n",
    "            \n",
    "            hidden = tf.compat.v1.layers.dense(last_conv_layer_flat, n_hidden, \n",
    "                                                activation=hidden_activation,\n",
    "                                                kernel_initializer=initializer)\n",
    "            \n",
    "            outputs = tf.compat.v1.layers.dense(hidden, n_outputs, \n",
    "                                                kernel_initializer=initializer)\n",
    "        \n",
    "        trainable_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \n",
    "                                                    scope=scope.name)\n",
    "        \n",
    "        trainable_vars_by_name = {var.name[len(scope.name):] : var for var in trainable_vars}\n",
    "\n",
    "        return outputs, trainable_vars_by_name\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "X_state = tf.compat.v1.placeholder(tf.float32, shape=[None, input_height, input_width, input_channels])\n",
    "online_q_values, online_vars = q_network(X_state=X_state, name='q_networks/online')\n",
    "target_q_values, target_vars = q_network(X_state=X_state, name='q_networks/target')\n",
    "\n",
    "copy_obs = [target_var.assign(online_vars[var_name]) for var_name, target_var in target_vars.items()]\n",
    "copy_online_to_target = tf.group(*copy_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_action = tf.compat.v1.placeholder(tf.int32, shape=[None])\n",
    "q_value = tf.reduce_sum(target_q_values * tf.one_hot(X_action, n_outputs), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.compat.v1.placeholder(tf.float32, shape=[None, 1])\n",
    "error = tf.abs(y - q_value)\n",
    "clipped_error = tf.clip_by_value(error, 0.0, 1.0)\n",
    "linear_error = 2*(error - clipped_error)\n",
    "loss = tf.compat.v1.reduce_mean(tf.square(clipped_error) +linear_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "optimizer = tf.compat.v1.train.MomentumOptimizer(learning_rate=learning_rate,name='momentum', momentum=0.9, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "saver = tf.compat.v1.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "replay_memory_size = 500000\n",
    "replay_memory = deque([], maxlen=replay_memory_size)\n",
    "\n",
    "def sample_memories(batch_size):\n",
    "    indicies = np.random.permutation(len(replay_memory))[:batch_size]\n",
    "    cols = [[], [], [], [], []] # state, action, rewards, next_state, continue\n",
    "    for idx in indicies:\n",
    "        memory = replay_memory[idx]\n",
    "        for col, value in zip(cols, memory):\n",
    "            col.append(value)\n",
    "    cols = [np.array(col) for col in cols]\n",
    "    return (cols[0], cols[1], cols[2].reshape(-1, 1), cols[3], cols[4].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor explore enviroment\n",
    "\n",
    "eps_min = 0.1\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 2000000\n",
    "\n",
    "def epsilon_greedy(q_values, step):\n",
    "    epsilon = max(eps_min, eps_max - (eps_max-eps_min) * step/eps_decay_steps)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        return np.argmax(q_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 400000\n",
    "training_start = 10000\n",
    "training_interval = 4\n",
    "save_steps = 500\n",
    "copy_steps = 10000\n",
    "discont_rate = 0.99\n",
    "skip_start = 90\n",
    "batch_size = 50\n",
    "iteration = 0\n",
    "checkpoint_path = './docking_dqn.ckpt'\n",
    "done = True\n",
    "rewards_counter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore session\n",
      "INFO:tensorflow:Restoring parameters from ./docking_dqn.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:13:35.315412: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-14 13:13:35.332417: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10501 iteration 1 rewards 0\n"
     ]
    }
   ],
   "source": [
    "running = True\n",
    "\n",
    "while True:\n",
    "\n",
    "\n",
    "\n",
    "    env = gym.make('space_docking-v0')\n",
    "    env.reset()\n",
    "\n",
    "    \n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        if os.path.isfile(checkpoint_path + '.index'):\n",
    "            print('restore session')\n",
    "            saver.restore(sess, checkpoint_path)\n",
    "        else:\n",
    "            init.run()\n",
    "            copy_online_to_target.run()\n",
    "        \n",
    "        while True:\n",
    "            step = global_step.eval()\n",
    "            if step >= n_steps:\n",
    "                break\n",
    "            iteration += 1\n",
    "            if done:\n",
    "                \n",
    "                if step > skip_start:\n",
    "                    print('episode', step, 'iteration', iteration ,'rewards', reward)\n",
    "\n",
    "\n",
    "                obs = env.reset()\n",
    "                for skip in range(skip_start):\n",
    "                    obs, reward, done, info = env.step(0)\n",
    "                state = preprocess_observations(obs)\n",
    "\n",
    "            # online dqn evaluate\n",
    "            q_values = online_q_values.eval(feed_dict={X_state: [state]})\n",
    "            action = epsilon_greedy(q_values, step)\n",
    "\n",
    "            # online dqn play\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            next_state = preprocess_observations(obs)\n",
    "\n",
    "            rewards_counter.append(rewards_counter)\n",
    "\n",
    "            # remember what happend\n",
    "            replay_memory.append((state, action, reward, next_state, 1.0 - done))\n",
    "            state = next_state\n",
    "            \n",
    "\n",
    "            if iteration < training_start or iteration % training_interval != 0:\n",
    "                continue # only train after warmup period and at regular intervals\n",
    "\n",
    "            # get probe from memory\n",
    "            # use target dqn to get target q value\n",
    "            X_state_val, X_action_val, rewards, X_next_state_val, continues = (\n",
    "                sample_memories(batch_size=batch_size))\n",
    "            \n",
    "            next_q_values = target_q_values.eval(\n",
    "                feed_dict={X_state: X_state_val})\n",
    "\n",
    "            max_next_q_values = np.max(next_q_values, axis=1, keepdims=True)\n",
    "            y_val = rewards + continues * discont_rate * max_next_q_values\n",
    "\n",
    "            # train online dqn\n",
    "            training_op.run(feed_dict={X_state: X_state_val, X_action: X_action_val, y: y_val})\n",
    "\n",
    "            # copy online dqn to target dqn\n",
    "            if step % copy_steps == 0:\n",
    "                print('copy network to target network')\n",
    "                copy_online_to_target.run()\n",
    "            \n",
    "            # save regulary\n",
    "            if step % save_steps == 0:\n",
    "                print('save checkpoint')\n",
    "                saver.save(sess, checkpoint_path)\n",
    "                break\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cool, actally no big errors....time to work on the enviroment, passing the right values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d2998af58360198af4f829ea7a2e55473ee9c83a4b3343387da68b4c68e0d61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('DA_Enviroment': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
