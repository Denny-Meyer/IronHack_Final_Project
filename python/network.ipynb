{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Docking Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "## !pip install -e ../gym_space_docking/\n",
    "\n",
    "loc = os.popen('pip3 show gym_space_docking').readlines()[7].split()[1]\n",
    "\n",
    "\n",
    "sys.path.append(loc)\n",
    "\n",
    "\n",
    "import gym\n",
    "import os\n",
    "import gym_space_docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include Network\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create enviroment pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "/Users/denny/Documents/workspace_ironhack/IronHack_Final_Project/gym_space_docking/gym_space_docking/envs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denny/Documents/workspace_ironhack/IronHack_Final_Project/gym_space_docking/gym_space_docking/envs/space_docking_env.py:55: Warning: no fast renderer available\n",
      "  self.window_display = pygame.display.set_mode(size=(window_width, window_height),flags= SCREENFLAGS)#, vsync=True)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('space_docking-v0')\n",
    "#print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "#print(env.observation_space)\n",
    "#print(type(env.action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    map, reward, done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(map, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocess_observations(map), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle observations\n",
    "\n",
    "# handle image scaling and resizing to fit the image in input data\n",
    "\n",
    "def preprocess_observations(obs):\n",
    "    # ToDo need love to work\n",
    "    img = obs\n",
    "    img = img.mean(axis=2)\n",
    "    img = (img - 128) / 128 -1\n",
    "\n",
    "    return img.reshape(88,80,1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create DQN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "input_height = 88\n",
    "input_width = 80\n",
    "input_channels = 1\n",
    "conv_n_maps = [32,64,64]\n",
    "conv_kernel_sizes = [(8,8), (4,4), (3,3)]\n",
    "conv_strides = [4, 2, 1]\n",
    "conv_paddings = ['SAME'] * 3\n",
    "conv_activation = [tf.nn.relu] * 3\n",
    "n_hidden_in = 64 * 11 * 10 # 64 maps with size 11x10\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n# -> ToDo define in enviroment \n",
    "initializer =  tf.keras.initializers.VarianceScaling()# tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state\n",
    "    with tf.compat.v1.variable_scope(name) as scope:\n",
    "        for n_maps, kernel_size, strides, padding, activation in zip(\n",
    "            conv_n_maps, conv_kernel_sizes, conv_strides,\n",
    "            conv_paddings, conv_activation):\n",
    "            \n",
    "            prev_layer = tf.compat.v1.layers.conv2d(\n",
    "                prev_layer, filters=n_maps, kernel_size= kernel_size,\n",
    "                strides= strides, padding=padding, activation=activation,\n",
    "                kernel_initializer= initializer)\n",
    "            \n",
    "            last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1, n_hidden_in])\n",
    "            \n",
    "            hidden = tf.compat.v1.layers.dense(last_conv_layer_flat, n_hidden, \n",
    "                                                activation=hidden_activation,\n",
    "                                                kernel_initializer=initializer)\n",
    "            \n",
    "            outputs = tf.compat.v1.layers.dense(hidden, n_outputs, \n",
    "                                                kernel_initializer=initializer)\n",
    "        \n",
    "        trainable_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \n",
    "                                                    scope=scope.name)\n",
    "        \n",
    "        trainable_vars_by_name = {var.name[len(scope.name):] : var for var in trainable_vars}\n",
    "\n",
    "        return outputs, trainable_vars_by_name\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "X_state = tf.compat.v1.placeholder(tf.float32, shape=[None, input_height, input_width, input_channels])\n",
    "online_q_values, online_vars = q_network(X_state=X_state, name='q_networks/online')\n",
    "target_q_values, target_vars = q_network(X_state=X_state, name='q_networks/target')\n",
    "\n",
    "copy_obs = [target_var.assign(online_vars[var_name]) for var_name, target_var in target_vars.items()]\n",
    "copy_online_to_target = tf.group(*copy_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_action = tf.compat.v1.placeholder(tf.int32, shape=[None])\n",
    "q_value = tf.reduce_sum(target_q_values * tf.one_hot(X_action, n_outputs), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.compat.v1.placeholder(tf.float32, shape=[None, 1])\n",
    "error = tf.abs(y - q_value)\n",
    "clipped_error = tf.clip_by_value(error, 0.0, 1.0)\n",
    "linear_error = 2*(error - clipped_error)\n",
    "loss = tf.compat.v1.reduce_mean(tf.square(clipped_error) +linear_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "optimizer = tf.compat.v1.train.MomentumOptimizer(learning_rate=learning_rate,name='momentum', momentum=0.9, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "saver = tf.compat.v1.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "replay_memory_size = 500000\n",
    "replay_memory = deque([], maxlen=replay_memory_size)\n",
    "\n",
    "def sample_memories(batch_size):\n",
    "    indicies = np.random.permutation(len(replay_memory))[:batch_size]\n",
    "    cols = [[], [], [], []] # state, action, rewards, next_state, continue\n",
    "    for idx in indicies:\n",
    "        memory = replay_memory[idx]\n",
    "        for col, value in zip(cols, memory):\n",
    "            col.append(value)\n",
    "    cols = [np.array(col) for col in cols]\n",
    "    return (cols[0], cols[1], cols[2].reshape(-1, 1), cols[3], cols[4].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor explore enviroment\n",
    "\n",
    "eps_min = 0.1\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 2000000\n",
    "\n",
    "def epsilon_greedy(q_values, step):\n",
    "    epsilon = max(eps_min, eps_max - (eps_max-eps_min) * step/eps_decay_steps)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        return np.argmax(q_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 4000000\n",
    "training_start = 10000\n",
    "training_interval = 4\n",
    "save_steps = 1000\n",
    "copy_steps = 10000\n",
    "discont_rate = 0.99\n",
    "skip_start = 90\n",
    "batch_size = 50\n",
    "iteration = 0\n",
    "checkpoint_path = './docking_dqn.ckpt'\n",
    "done = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-12 17:00:51.246717: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-12 17:00:51.319098: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 5) astro_85\n",
      "(18, 4) astro_85\n",
      "(19, 3) astro_85\n",
      "(17, 4) astro_85\n",
      "(17, 4) astro_85\n",
      "(19, 3) astro_85\n",
      "(20, 2) astro_85\n",
      "(19, 4) astro_85\n",
      "(20, 4) astro_85\n",
      "(20, 3) astro_85\n",
      "(22, 3) astro_85\n",
      "(22, 4) astro_85\n",
      "(21, 4) astro_85\n",
      "(21, 5) astro_85\n",
      "(16, 5) astro_85\n",
      "(17, 4) astro_85\n",
      "(18, 4) astro_85\n",
      "(16, 4) astro_85\n",
      "(16, 4) astro_85\n",
      "(16, 4) astro_85\n",
      "(14, 4) astro_85\n",
      "(14, 4) astro_85\n",
      "(7, 4) astro_85\n",
      "(7, 4) astro_85\n",
      "(11, 3) astro_85\n",
      "(10, 2) astro_85\n",
      "(9, 2) astro_85\n",
      "(7, 2) astro_85\n",
      "(7, 1) astro_85\n",
      "(4, 2) astro_85\n",
      "(1, 2) astro_85\n",
      "(1, 3) astro_85\n",
      "(1, 3) astro_85\n",
      "(1, 3) astro_85\n",
      "(1, 3) astro_85\n",
      "(1, 4) astro_85\n",
      "(21, 26) astro_94\n",
      "(20, 24) astro_94\n",
      "(20, 21) astro_94\n",
      "(20, 18) astro_94\n",
      "(18, 17) astro_94\n",
      "(18, 14) astro_94\n",
      "(16, 14) astro_94\n",
      "(16, 11) astro_94\n",
      "(15, 10) astro_94\n",
      "(14, 9) astro_94\n",
      "(12, 8) astro_94\n",
      "(12, 7) astro_94\n",
      "(10, 6) astro_94\n",
      "(10, 5) astro_94\n",
      "(8, 5) astro_94\n",
      "(7, 4) astro_94\n",
      "(5, 3) astro_94\n",
      "(5, 3) astro_94\n",
      "(5, 2) astro_94\n",
      "(3, 3) astro_94\n",
      "(5, 3) astro_94\n",
      "(5, 2) astro_94\n",
      "(5, 2) astro_94\n",
      "(4, 3) astro_94\n",
      "(4, 3) astro_94\n",
      "(4, 2) astro_94\n",
      "(4, 3) astro_94\n",
      "(4, 3) astro_94\n",
      "(3, 2) astro_94\n",
      "(29, 4) astro_57\n",
      "(29, 3) astro_57\n",
      "(29, 3) astro_57\n",
      "(28, 3) astro_57\n",
      "(29, 3) astro_57\n",
      "(27, 3) astro_57\n",
      "(29, 3) astro_57\n",
      "(29, 3) astro_57\n",
      "(28, 4) astro_57\n",
      "(27, 3) astro_57\n",
      "(27, 3) astro_57\n",
      "(26, 2) astro_57\n",
      "(26, 3) astro_57\n",
      "(26, 3) astro_57\n",
      "(27, 4) astro_57\n",
      "(27, 4) astro_57\n",
      "(28, 5) astro_57\n",
      "(29, 5) astro_57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/83__n5jj77s0p9pv81ccxck40000gn/T/ipykernel_4194/1802260584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# online dqn evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monline_q_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_greedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \"\"\"\n\u001b[0;32m--> 921\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use ref() instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5510\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5511\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5512\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_path + '.index'):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "        copy_online_to_target.run()\n",
    "    \n",
    "    while True:\n",
    "        step = global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "        iteration += 1\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            for skip in range(skip_start):\n",
    "                obs, reward, done, info = env.step(0)\n",
    "            state = preprocess_observations(obs)\n",
    "\n",
    "        # online dqn evaluate\n",
    "        q_values = online_q_values.eval(feed_dict={X_state: [state]})\n",
    "        action = epsilon_greedy(q_values, step)\n",
    "\n",
    "        # online dqn play\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_observations(obs)\n",
    "\n",
    "        # remember what happend\n",
    "        replay_memory.append((state, action, reward, next_state, 1.0 - done))\n",
    "        state = next_state\n",
    "\n",
    "        if iteration < training_start or iteration % training_interval != 0:\n",
    "            continue # only train after warmup period and at regular intervals\n",
    "\n",
    "        # get probe from memory\n",
    "        # use target dqn to get target q value\n",
    "        X_state_val, X_action_val, rewards, X_next_state_val, continues = (\n",
    "            sample_memories(batch_size=batch_size))\n",
    "        \n",
    "        next_q_values = target_q_values.eval(\n",
    "            feed_dict={X_state: X_state_val})\n",
    "\n",
    "        max_next_q_values = np.max(next_q_values, axis=1, keepdims=True)\n",
    "        y_val = rewards + continues * discont_rate * max_next_q_values\n",
    "\n",
    "        # train online dqn\n",
    "        training_op.run(feed_dict={X_state: X_state_val, X_action: X_action_val, y: y_val})\n",
    "\n",
    "        # copy online dqn to target dqn\n",
    "        if step % copy_steps == 0:\n",
    "            copy_online_to_target.run()\n",
    "        \n",
    "        # save regulary\n",
    "        if step % save_steps == 0:\n",
    "            saver.save(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cool, actally no big errors....time to work on the enviroment, passing the right values"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d2998af58360198af4f829ea7a2e55473ee9c83a4b3343387da68b4c68e0d61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('DA_Enviroment': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
