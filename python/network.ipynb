{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Docking Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "## !pip install -e ../gym_space_docking/\n",
    "\n",
    "loc = os.popen('pip3 show gym_space_docking').readlines()[7].split()[1]\n",
    "\n",
    "\n",
    "sys.path.append(loc)\n",
    "\n",
    "\n",
    "import gym\n",
    "import os\n",
    "import gym_space_docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include Network\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create enviroment pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "/home/meyd/Documents/GitHub/Denny-Meyer/IronHack_Final_Project/gym_space_docking/gym_space_docking/envs\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('space_docking-v0')\n",
    "#print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "#print(env.observation_space)\n",
    "#print(type(env.action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle observations\n",
    "\n",
    "# handle image scaling and resizing to fit the image in input data\n",
    "\n",
    "def preprocess_observations(obs):\n",
    "    # ToDo need love to work\n",
    "    img = obs\n",
    "    img = img.mean(axis=2)\n",
    "    img = (img - 128) / 128 -1\n",
    "\n",
    "    return img.reshape(88,80,1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    map, reward, done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(map, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocess_observations(map), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create DQN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "input_height = 88\n",
    "input_width = 80\n",
    "input_channels = 1\n",
    "conv_n_maps = [32,64,64]\n",
    "conv_kernel_sizes = [(8,8), (4,4), (3,3)]\n",
    "conv_strides = [4, 2, 1]\n",
    "conv_paddings = ['SAME'] * 3\n",
    "conv_activation = [tf.nn.relu] * 3\n",
    "n_hidden_in = 64 * 11 * 10 # 64 maps with size 11x10\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n# -> ToDo define in enviroment \n",
    "initializer =  tf.keras.initializers.VarianceScaling()# tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state\n",
    "    with tf.compat.v1.variable_scope(name) as scope:\n",
    "        for n_maps, kernel_size, strides, padding, activation in zip(\n",
    "            conv_n_maps, conv_kernel_sizes, conv_strides,\n",
    "            conv_paddings, conv_activation):\n",
    "            \n",
    "            prev_layer = tf.compat.v1.layers.conv2d(\n",
    "                prev_layer, filters=n_maps, kernel_size= kernel_size,\n",
    "                strides= strides, padding=padding, activation=activation,\n",
    "                kernel_initializer= initializer)\n",
    "            \n",
    "            last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1, n_hidden_in])\n",
    "            \n",
    "            hidden = tf.compat.v1.layers.dense(last_conv_layer_flat, n_hidden, \n",
    "                                                activation=hidden_activation,\n",
    "                                                kernel_initializer=initializer)\n",
    "            \n",
    "            outputs = tf.compat.v1.layers.dense(hidden, n_outputs, \n",
    "                                                kernel_initializer=initializer)\n",
    "        \n",
    "        trainable_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \n",
    "                                                    scope=scope.name)\n",
    "        \n",
    "        trainable_vars_by_name = {var.name[len(scope.name):] : var for var in trainable_vars}\n",
    "\n",
    "        return outputs, trainable_vars_by_name\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meyd/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "/home/meyd/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/home/meyd/anaconda3/envs/DA_Enviroment/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "X_state = tf.compat.v1.placeholder(tf.float32, shape=[None, input_height, input_width, input_channels])\n",
    "online_q_values, online_vars = q_network(X_state=X_state, name='q_networks/online')\n",
    "target_q_values, target_vars = q_network(X_state=X_state, name='q_networks/target')\n",
    "\n",
    "copy_obs = [target_var.assign(online_vars[var_name]) for var_name, target_var in target_vars.items()]\n",
    "copy_online_to_target = tf.group(*copy_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_action = tf.compat.v1.placeholder(tf.int32, shape=[None])\n",
    "q_value = tf.reduce_sum(target_q_values * tf.one_hot(X_action, n_outputs), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.compat.v1.placeholder(tf.float32, shape=[None, 1])\n",
    "error = tf.abs(y - q_value)\n",
    "clipped_error = tf.clip_by_value(error, 0.0, 1.0)\n",
    "linear_error = 2*(error - clipped_error)\n",
    "loss = tf.compat.v1.reduce_mean(tf.square(clipped_error) +linear_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "optimizer = tf.compat.v1.train.MomentumOptimizer(learning_rate=learning_rate,name='momentum', momentum=0.9, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "saver = tf.compat.v1.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "replay_memory_size = 500000\n",
    "replay_memory = deque([], maxlen=replay_memory_size)\n",
    "\n",
    "def sample_memories(batch_size):\n",
    "    indicies = np.random.permutation(len(replay_memory))[:batch_size]\n",
    "    cols = [[], [], [], [], []] # state, action, rewards, next_state, continue\n",
    "    for idx in indicies:\n",
    "        memory = replay_memory[idx]\n",
    "        for col, value in zip(cols, memory):\n",
    "            col.append(value)\n",
    "    cols = [np.array(col) for col in cols]\n",
    "    return (cols[0], cols[1], cols[2].reshape(-1, 1), cols[3], cols[4].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor explore enviroment\n",
    "\n",
    "eps_min = 0.1\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 2000000\n",
    "\n",
    "def epsilon_greedy(q_values, step):\n",
    "    epsilon = max(eps_min, eps_max - (eps_max-eps_min) * step/eps_decay_steps)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(n_outputs)\n",
    "    else:\n",
    "        return np.argmax(q_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 400000\n",
    "training_start = 10000\n",
    "training_interval = 4\n",
    "save_steps = 500\n",
    "copy_steps = 10000\n",
    "discont_rate = 0.99\n",
    "skip_start = 90\n",
    "batch_size = 50\n",
    "iteration = 0\n",
    "checkpoint_path = './docking_dqn.ckpt'\n",
    "done = True\n",
    "rewards_counter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 10:42:00.993915: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-14 10:42:00.994148: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-14 10:42:00.994551: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-12-14 10:42:01.002201: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2021-12-14 10:42:01.030745: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599990000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 8) astro_49\n",
      "collide\n",
      "(41, 15) astro_19\n",
      "collide\n",
      "(19, 13) astro_30\n",
      "collide\n",
      "(32, 41) astro_23\n",
      "collide\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_path + '.index'):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "        copy_online_to_target.run()\n",
    "    \n",
    "    while True:\n",
    "        step = global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "        iteration += 1\n",
    "        if done:\n",
    "            \n",
    "            if step > skip_start:\n",
    "                print('run', step, 'rewards', reward)\n",
    "\n",
    "\n",
    "            obs = env.reset()\n",
    "            for skip in range(skip_start):\n",
    "                obs, reward, done, info = env.step(0)\n",
    "            state = preprocess_observations(obs)\n",
    "\n",
    "        # online dqn evaluate\n",
    "        q_values = online_q_values.eval(feed_dict={X_state: [state]})\n",
    "        action = epsilon_greedy(q_values, step)\n",
    "\n",
    "        # online dqn play\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_observations(obs)\n",
    "\n",
    "        rewards_counter.append(rewards_counter)\n",
    "\n",
    "        # remember what happend\n",
    "        replay_memory.append((state, action, reward, next_state, 1.0 - done))\n",
    "        state = next_state\n",
    "        \n",
    "\n",
    "        if iteration < training_start or iteration % training_interval != 0:\n",
    "            continue # only train after warmup period and at regular intervals\n",
    "\n",
    "        # get probe from memory\n",
    "        # use target dqn to get target q value\n",
    "        X_state_val, X_action_val, rewards, X_next_state_val, continues = (\n",
    "            sample_memories(batch_size=batch_size))\n",
    "        \n",
    "        next_q_values = target_q_values.eval(\n",
    "            feed_dict={X_state: X_state_val})\n",
    "\n",
    "        max_next_q_values = np.max(next_q_values, axis=1, keepdims=True)\n",
    "        y_val = rewards + continues * discont_rate * max_next_q_values\n",
    "\n",
    "        # train online dqn\n",
    "        training_op.run(feed_dict={X_state: X_state_val, X_action: X_action_val, y: y_val})\n",
    "\n",
    "        # copy online dqn to target dqn\n",
    "        if step % copy_steps == 0:\n",
    "            copy_online_to_target.run()\n",
    "        \n",
    "        # save regulary\n",
    "        if step % save_steps == 0:\n",
    "            saver.save(sess, checkpoint_path)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cool, actally no big errors....time to work on the enviroment, passing the right values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d2998af58360198af4f829ea7a2e55473ee9c83a4b3343387da68b4c68e0d61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('DA_Enviroment': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
